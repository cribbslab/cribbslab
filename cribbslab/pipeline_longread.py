"""===========================
Pipeline longread
===========================

Overview
========

This pipeline performs analysis of bulk long-read RNA-seq data (ONT).
The workflow includes preprocessing, alignment, transcript identification
using bambu, and comprehensive QC metrics.

Usage
=====

To run locally:

    python pipeline_longread.py make full --local

Configuration
-------------

The pipeline requires a configured :file:`pipeline.yml` file.

Default configuration files can be generated by executing:

   python <srcdir>/pipeline_longread.py config

Input files
-----------

* Fastq files from ONT sequencing (*.fastq.gz or *.fastq)
* Reference genome (fasta)
* Annotation file (GTF)

Requirements
------------

* minimap2 - for splice-aware alignment
* samtools - for BAM processing
* pychopper - for cDNA preprocessing (optional)
* seqtk - for subsampling
* NanoPlot - for long-read QC
* RSeQC - for read distribution and gene body coverage
* bedtools - for coverage analysis
* bambu (R package) - for transcript identification
* biokit - for read length statistics

Pipeline output
===============

* Aligned BAM files
* Bambu transcript quantification (counts, TPM)
* Novel transcript GTF
* Comprehensive QC reports (NanoPlot, RSeQC, read lengths)
* MultiQC aggregated report

Processing steps
================

1. (Optional) Pychopper preprocessing for cDNA
2. (Optional) Subsampling to target read count
3. Minimap2 splice-aware alignment
4. Bambu transcript discovery and quantification
5. QC metrics:
   - Read length distributions
   - NanoPlot statistics
   - Read mapping distribution
   - Gene body coverage
   - Bedtools coverage

Code
====

"""

import sys
import os
from ruffus import *
import cgatcore.pipeline as P
import cgatcore.experiment as E

# load options from the config file
PARAMS = P.get_parameters(
    ["%s/pipeline.yml" % os.path.splitext(__file__)[0],
     "../pipeline.yml",
     "pipeline.yml"])


SEQUENCESUFFIXES = ("*.fastq.gz",
                    "*.fastq",
                    "*.fq.gz",
                    "*.fq")

SEQUENCEFILES = tuple([os.path.join('.', suffix_name)
                       for suffix_name in SEQUENCESUFFIXES])

SEQUENCEFILES_REGEX = regex(
    r".*/(\S+)\.(fastq\.gz|fastq|fq\.gz|fq)")


# -----------------------------------------------
# Preprocessing: Pychopper (cDNA only)
# -----------------------------------------------

@follows(mkdir("pychopper"))
@active_if(PARAMS.get("pychopper_run", False))
@transform(SEQUENCEFILES,
           SEQUENCEFILES_REGEX,
           r"pychopper/\1.pychopper.fastq")
def run_pychopper(infile, outfile):
    """
    Run pychopper for cDNA preprocessing to identify and orient full-length reads.
    This step is recommended for cDNA but not for direct RNA.

    Parameters from pipeline.yml:
        pychopper_kit: library prep kit version (e.g., PCS111)
        pychopper_options: additional options
    """

    basename = os.path.basename(outfile).replace(".fastq", "")
    report_pdf = outfile.replace(".fastq", ".report.pdf")

    job_threads = PARAMS.get("pychopper_threads", 8)
    job_memory = PARAMS.get("pychopper_memory", "4G")

    statement = """
        pychopper -U 
        -k %(pychopper_kit)s 
        -z %(pychopper_rescue_length)s 
        -r %(report_pdf)s 
        -t %(job_threads)s 
        %(pychopper_options)s 
        %(infile)s 
        %(outfile)s
    """

    P.run(statement)


# -----------------------------------------------
# Preprocessing: Subsampling (optional)
# -----------------------------------------------

def get_input_for_subsample():
    """Determine input files for subsampling based on whether pychopper was run."""
    if PARAMS.get("pychopper_run", False):
        return "pychopper/*.pychopper.fastq"
    else:
        return SEQUENCEFILES


@follows(mkdir("subsampled"))
@active_if(PARAMS.get("subsample_run", False))
@transform(get_input_for_subsample(),
           regex(r".*/(\S+)\.(pychopper\.fastq|fastq\.gz|fastq|fq\.gz|fq)"),
           r"subsampled/\1.subsampled.fastq")
def subsample_reads(infile, outfile):
    """
    Subsample reads to a target number using seqtk.
    Useful for standardizing read depth across samples.

    Parameters from pipeline.yml:
        subsample_target: target number of reads (e.g., 4000000)
        subsample_seed: random seed for reproducibility
    """

    target_reads = PARAMS.get("subsample_target", 4000000)
    seed = PARAMS.get("subsample_seed", 200)

    statement = """
        seqtk sample -s%(seed)s %(infile)s %(target_reads)s > %(outfile)s
    """

    P.run(statement)


# -----------------------------------------------
# Alignment with minimap2
# -----------------------------------------------

def get_input_for_alignment():
    """Determine input files for alignment based on preprocessing steps."""
    if PARAMS.get("subsample_run", False):
        return "subsampled/*.subsampled.fastq"
    elif PARAMS.get("pychopper_run", False):
        return "pychopper/*.pychopper.fastq"
    else:
        return SEQUENCEFILES


@follows(mkdir("aligned"))
@transform(get_input_for_alignment(),
           regex(r".*/(\S+)\.(subsampled\.fastq|pychopper\.fastq|fastq\.gz|fastq|fq\.gz|fq)"),
           r"aligned/\1.bam")
def align_minimap2(infile, outfile):
    """
    Align reads using minimap2 with splice-aware settings for long-read RNA-seq.
    Uses -ax splice for spliced alignment and -uf for stranded RNA-seq.

    Parameters from pipeline.yml:
        genome_fasta: path to reference genome fasta
        minimap2_options: additional minimap2 options
        minimap2_threads: number of threads
    """

    job_threads = PARAMS.get("minimap2_threads", 16)
    job_memory = PARAMS.get("minimap2_memory", "8G")

    genome_fasta = PARAMS["genome_fasta"]
    minimap2_options = PARAMS.get("minimap2_options", "-ax splice -uf -p 0.9")

    statement = """
        minimap2 %(minimap2_options)s 
        -t %(job_threads)s 
        %(genome_fasta)s 
        %(infile)s 
        | samtools sort -@ %(job_threads)s -O bam -o %(outfile)s - 
        && samtools index %(outfile)s
    """

    P.run(statement)


# -----------------------------------------------
# QC: Read lengths (fastq)
# -----------------------------------------------

def get_input_for_readlengths():
    """Determine input files for read length QC."""
    if PARAMS.get("subsample_run", False):
        return "subsampled/*.subsampled.fastq"
    elif PARAMS.get("pychopper_run", False):
        return "pychopper/*.pychopper.fastq"
    else:
        return SEQUENCEFILES


@follows(mkdir("qc_readlengths"))
@transform(get_input_for_readlengths(),
           regex(r".*/(\S+)\.(subsampled\.fastq|pychopper\.fastq|fastq\.gz|fastq|fq\.gz|fq)"),
           r"qc_readlengths/\1.readlengths.txt")
def qc_read_lengths(infile, outfile):
    """
    Calculate read length statistics using biokit.
    Provides distribution of read lengths for long-read data.
    """

    statement = """
        biokit fastq_read_lengths -v %(infile)s -o %(outfile)s
    """

    P.run(statement)


# -----------------------------------------------
# QC: NanoPlot (BAM)
# -----------------------------------------------

@follows(mkdir("qc_nanoplot"))
@transform(align_minimap2,
           regex(r"aligned/(\S+)\.bam"),
           r"qc_nanoplot/\1/NanoStats.txt")
def qc_nanoplot(infile, outfile):
    """
    Run NanoPlot on aligned BAM files to generate long-read specific QC metrics.
    Outputs include read length distributions, quality scores, and mapping statistics.
    """

    outdir = os.path.dirname(outfile)

    job_threads = PARAMS.get("nanoplot_threads", 4)
    job_memory = PARAMS.get("nanoplot_memory", "8G")

    statement = """
        NanoPlot --bam %(infile)s 
        -o %(outdir)s 
        --tsv_stats 
        --plots dot 
        -t %(job_threads)s
    """

    P.run(statement)


# -----------------------------------------------
# QC: Read distribution (RSeQC)
# -----------------------------------------------

@follows(mkdir("qc_read_distribution"))
@transform(align_minimap2,
           regex(r"aligned/(\S+)\.bam"),
           r"qc_read_distribution/\1.read_distribution.txt")
def qc_read_distribution(infile, outfile):
    """
    Calculate read mapping distribution across genomic features using RSeQC.
    Shows proportion of reads mapping to CDS, UTRs, introns, intergenic regions.

    Parameters from pipeline.yml:
        rseqc_bed: BED12 annotation file for RSeQC
    """

    rseqc_bed = PARAMS["rseqc_bed"]

    statement = """
        read_distribution.py -i %(infile)s -r %(rseqc_bed)s > %(outfile)s
    """

    P.run(statement)


# -----------------------------------------------
# QC: Gene body coverage (RSeQC)
# -----------------------------------------------

@follows(mkdir("qc_genebody"))
@collate(align_minimap2,
         regex(r"aligned/(\S+)\.bam"),
         r"qc_genebody/genebody_coverage.geneBodyCoverage.txt")
def qc_genebody_coverage(infiles, outfile):
    """
    Calculate gene body coverage using RSeQC.
    Assesses 5' to 3' coverage uniformity across transcripts.

    Parameters from pipeline.yml:
        genebody_bed: BED12 file with CDS regions (preferably >1000bp transcripts)
    """

    outprefix = outfile.replace(".geneBodyCoverage.txt", "")
    genebody_bed = PARAMS["genebody_bed"]

    # Create a file with list of BAM files
    bam_list = os.path.join(os.path.dirname(outfile), "bam_files.txt")

    with open(bam_list, "w") as f:
        for infile in infiles:
            f.write(infile + "\n")

    statement = """
        geneBody_coverage.py -r %(genebody_bed)s 
        -i %(bam_list)s 
        -o %(outprefix)s
    """

    P.run(statement, job_memory="16G")


# -----------------------------------------------
# QC: Bedtools coverage
# -----------------------------------------------

@follows(mkdir("qc_bedtools_coverage"))
@transform(align_minimap2,
           regex(r"aligned/(\S+)\.bam"),
           r"qc_bedtools_coverage/\1.coverage.txt")
def qc_bedtools_coverage(infile, outfile):
    """
    Calculate coverage across genomic features using bedtools.

    Parameters from pipeline.yml:
        bedtools_bed: BED annotation file for coverage calculation
    """

    bedtools_bed = PARAMS["bedtools_bed"]

    statement = """
        bedtools coverage -a %(bedtools_bed)s -b %(infile)s > %(outfile)s
    """

    P.run(statement, job_memory="8G")


# -----------------------------------------------
# Bambu: Transcript discovery and quantification
# -----------------------------------------------

@follows(mkdir("bambu"))
@merge(align_minimap2, "bambu/bambu_output.sentinel")
def run_bambu(infiles, outfile):
    """
    Run bambu for transcript discovery and quantification.
    Bambu identifies novel transcripts and quantifies expression.

    Parameters from pipeline.yml:
        bambu_gtf: annotation GTF file
        bambu_fasta: reference genome fasta
        bambu_prefix: output file prefix
        bambu_threads: number of cores for parallel processing
    """

    R_SRC_PATH = os.path.abspath(os.path.join(os.path.dirname(__file__), "R"))

    bam_dir = "aligned"
    outdir = "bambu"

    job_threads = PARAMS.get("bambu_threads", 8)
    job_memory = PARAMS.get("bambu_memory", "64G")

    statement = """
        Rscript %(R_SRC_PATH)s/bambu.R 
        --bam_dir %(bam_dir)s 
        --gtf %(bambu_gtf)s 
        --genome %(bambu_fasta)s 
        --outdir %(outdir)s 
        --prefix %(bambu_prefix)s 
        --threads %(job_threads)s 
        && touch %(outfile)s
    """

    P.run(statement)


# -----------------------------------------------
# MultiQC: Aggregate QC reports
# -----------------------------------------------

@follows(qc_nanoplot, qc_read_distribution, qc_genebody_coverage, qc_bedtools_coverage, qc_read_lengths)
@merge([align_minimap2, "qc_nanoplot/*", "qc_read_distribution/*", "qc_genebody/*"],
       "multiqc/multiqc_report.html")
def multiqc(infiles, outfile):
    """
    Aggregate all QC reports using MultiQC.
    """

    outdir = os.path.dirname(outfile)

    statement = """
        export LC_ALL=en_US.UTF-8 &&
        export LANG=en_US.UTF-8 &&
        multiqc -f -n multiqc_report.html -o %(outdir)s .
    """

    P.run(statement)


# -----------------------------------------------
# Pipeline targets
# -----------------------------------------------

@follows(run_bambu, multiqc)
def full():
    """
    Run the complete pipeline including alignment, bambu quantification, and all QC.
    """
    pass


@follows(align_minimap2)
def align():
    """
    Run alignment only.
    """
    pass


@follows(qc_nanoplot, qc_read_distribution, qc_genebody_coverage, qc_bedtools_coverage, qc_read_lengths, multiqc)
def qc():
    """
    Run QC only (requires aligned BAM files).
    """
    pass


@follows(run_bambu)
def bambu():
    """
    Run bambu only (requires aligned BAM files).
    """
    pass


def main(argv=None):
    if argv is None:
        argv = sys.argv
    P.main(argv)


if __name__ == "__main__":
    sys.exit(P.main(sys.argv))
